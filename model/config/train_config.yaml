# config/train_config.yaml

# --- DataModule Arguments (Static for this CV run) ---
data:
  data_dir_train_val: "data/AZH_dataset/Train" # todo: Set training data path
  # For predownloaded models
#  processor_path: "model/hf_models/Jayanth2002_dinov2_finetuned_skin"
  # data_dir_test: null # Will be overridden if provided in run_kfold.py
  num_classes: 6        # Set your number of classes
  size: 224
  batch_size: 64
  workers: 4
  # Select for K-fold CV or training/validation split
  k_fold_num_splits: 1    # Set to 1 for training/validation split, not K-fold
  validation_split_ratio: 0.2
  k_fold_random_seed: 1  # todo
  resize_first: false
  crop_scale_wound: [0.6, 1.0]
  color_jitter_brightness: 0.2
  color_jitter_contrast: 0.2
  color_jitter_saturation: 0.2
  color_jitter_hue: 0.1
  flip_prob: 0.5
  erase_prob: 0.0
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# --- ClassificationModel Arguments (Static for this CV run) ---
model:
  model_name: "vit-b16-224-in21k-wound"  # todo: Set model name
  # For predownloaded models
#  model_path: "model/hf_models/Jayanth2002_dinov2_finetuned_skin"
  training_mode: "full" # Options: "full", "lora", "linear"
  optimizer: "adamw"
  lr: 1.0965e-05  # todo: 0.0001, 0.00005, 0.00001
  weight_decay: 0.01  # todo
  scheduler: "cosine"
  warmup_steps: 50  # todo: 500, 总 steps 的 5-10%?
  # lora_r: 16 # Only if training_mode is lora
  # lora_alpha: 16

# --- Trainer Arguments (Some static, some will be overridden) ---
trainer:
  max_epochs: 100
  accelerator: "gpu"
  devices: "1"
  precision: "16-mixed"
  #  max_steps: 5000
#  val_check_interval: 500
  logger:
#    save_dir: "output"
    name: "run_logs"
  callbacks:
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: "val_acc"
        patience: 10
        min_delta: 0.001
        mode: "max"
        verbose: true
    # Add other callbacks as needed

# --- ModelCheckpoint (Defaults set in MyLightningCLI can be overridden here) ---
model_checkpoint:
  filename: "best-step-{step}-{val_acc:.4f}" # val_macro_f1
  monitor: "val_acc" # val_macro_f1
  save_last: true
  mode: "max" # "min" for loss, "max" for accuracy
  save_top_k: 1
